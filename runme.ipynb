{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from moviepy.editor import VideoFileClip\n",
    "\n",
    "\n",
    "def grayscale(img):\n",
    "    \"\"\"\n",
    "    Returns a gray scale version of the image, obtained by stripping the red and green channel,\n",
    "    and keeping the blue channel only. Blue channel allows detection of a yellow lane mark in\n",
    "    bright light. Input images must be in an RGB color space.\n",
    "    \"\"\"\n",
    "    return cv2.split(img)[2]\n",
    "\n",
    "\n",
    "def region_of_interest(img, vertices):\n",
    "    \"\"\"\n",
    "    Applies an image mask. Only keeps the region of the image defined by the polygon\n",
    "    formed from the given vertices. The rest of the image is set to black.\n",
    "    \"\"\"\n",
    "    # defining a blank mask to start with\n",
    "    mask = np.zeros_like(img)\n",
    "\n",
    "    # defining a 3 channel or 1 channel color to fill the mask with depending on the input image\n",
    "    if len(img.shape) > 2:\n",
    "        channel_count = img.shape[2]  # i.e. 3 or 4 depending on your image\n",
    "        ignore_mask_color = (255,) * channel_count\n",
    "    else:\n",
    "        ignore_mask_color = 255\n",
    "\n",
    "    # filling pixels inside the polygon defined by \"vertices\" with the fill color\n",
    "    cv2.fillPoly(mask, [vertices], ignore_mask_color)\n",
    "\n",
    "    # returning the image only where mask pixels are nonzero\n",
    "    masked_image = cv2.bitwise_and(img, mask)\n",
    "    return masked_image\n",
    "\n",
    "\n",
    "def weighted_img(img, initial_img, α=0.8, β=1., λ=0.):\n",
    "    \"\"\"\n",
    "    `img` is the output of a Hough transform\n",
    "    Should be a blank image (all black) with lines drawn on it.\n",
    "\n",
    "    `initial_img` should be the image before any processing.\n",
    "\n",
    "    The result image is computed as follows:\n",
    "\n",
    "    initial_img * α + img * β + λ\n",
    "    NOTE: initial_img and img must be the same shape!\n",
    "    \"\"\"\n",
    "    return cv2.addWeighted(initial_img, α, img, β, λ)\n",
    "\n",
    "\n",
    "def line_slope(x0, y0, x1, y1):\n",
    "    \"\"\"\n",
    "    Returns the slope of the line going through points (x0, y0) and (x1, y1), i.e. the m coefficient in y=m*x+q;\n",
    "    but if x0==x1 , i.e. the line is parallel to the y axis, returns inf\n",
    "    \"\"\"\n",
    "    slope = float('inf') if x0 == x1 else (y0 - y1) / (x0 - x1)\n",
    "    return slope\n",
    "\n",
    "\n",
    "def line_intercept(x0, y0, x1, y1):\n",
    "    \"\"\"\n",
    "    Returns the intercept of the line going through points (x0, y0) and (x1, y1), i.e. the q coefficient in y=m*x+q;\n",
    "    but if x0==x1 , i.e. the line is parallel to the y axis, returns inf\n",
    "    \"\"\"\n",
    "    intercept = float('inf') if x0 == x1 else (x1 * y0 - x0 * y1) / (x1 - x0)\n",
    "    return intercept\n",
    "\n",
    "\n",
    "def get_Hough_segments(image, vertices, kernel_size, threshold1, threshold2, rho, theta, min_votes, min_line_length,\n",
    "                       max_line_gap):\n",
    "    \"\"\"\n",
    "    Detect segments within an area of interest in an RGB image. The method first converts the image to grayscale,\n",
    "    then applies a Gaussian blur, runs a Canny edge detection, discards detected edges that are outside the mask,\n",
    "    and then runs a probabilistic Hough transform to fetch the list of segments.\n",
    "\n",
    "    :param image: the input image, to be processed\n",
    "    :param vertices: the mask, a list of its vertices\n",
    "    :param kernel_size: kernel size for the Gaussian blur\n",
    "    :param threshold1: lower threshold for Canny edge detection\n",
    "    :param threshold2: upper threshold for Canny edge detection\n",
    "    :param rho: distance resolution in pixels of the Hough grid\n",
    "    :param theta: angular resolution in radians of the Hough grid\n",
    "    :param min_votes: minimum number of votes for a line to be considered by the Hough transform\n",
    "    :param min_line_length: minimum length in pixels of segments\n",
    "    :param max_line_gap: maximum allowed gaps in pixels between connectable line segments\n",
    "    :return: the list of detected segments, formatted as [segment0, segment1, ...], where each segment is formatted as\n",
    "    array([x0, y0, x1, y1], dtype=int32), with x0, y0, x1 and y1 the coordinates of the segment endpoints\n",
    "    \"\"\"\n",
    "\n",
    "    # Go grayscale\n",
    "    gscale_image = grayscale(image)\n",
    "\n",
    "    # Do the Gaussian blur\n",
    "    blur_gray = cv2.GaussianBlur(gscale_image, (kernel_size, kernel_size), 0)\n",
    "\n",
    "    # Run a Canny edge detection\n",
    "    edges = cv2.Canny(blur_gray, threshold1, threshold2)\n",
    "\n",
    "    # Apply a bitmask to set to black all pixels outside the are of interest.\n",
    "    masked = region_of_interest(edges, vertices)\n",
    "\n",
    "    rho = 1  # distance resolution in pixels of the Hough grid\n",
    "    theta = np.pi / 720  # angular resolution in radians of the Hough grid\n",
    "    min_votes = 25  # minimum number of votes (intersections in Hough grid cell)\n",
    "    min_line_length = 10  # minimum number of pixels making up a line\n",
    "    max_line_gap = 50  # maximum gap in pixels between connectable line segments\n",
    "    segments = cv2.HoughLinesP(masked,\n",
    "                               rho,\n",
    "                               theta,\n",
    "                               min_votes,\n",
    "                               np.array([]),\n",
    "                               minLineLength=min_line_length,\n",
    "                               maxLineGap=max_line_gap)\n",
    "    # cv2.HoughLinesP() returns a list like [[[segment1]],[[segment2]],...], so unpack the segments and make a list like\n",
    "    # [[segment1],[segment2],...]\n",
    "    segments = [segment[0] for segment in segments]\n",
    "\n",
    "    return segments\n",
    "\n",
    "\n",
    "def get_lanes(segments, vertices, min_slope):\n",
    "    \"\"\"\n",
    "    Identifies the left and right lane markings based on segments obtained by a Hough transform.\n",
    "    Segments with a slope below `min_slope` are ignored. The returned lane markings are extended/trimmed vertically\n",
    "    based on the `vertices` mask, used to mask the input to the Hough transform.\n",
    "    Endpoint of the left and right lane markings are returned as a list of two tuples:\n",
    "    [(left_x0, left_y0, left_x1, left_y1), (right_x0, right_y0, right_x1, right_y1)]\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    ''' To fit a continuous line on the left, interpolate all endpoints of identified segments with a negative\n",
    "    slope; to fit a continuous line on the right, do the same with endpoints of segments with a positive\n",
    "    slope. Slope is the m parameter in the 2D line equation y=m*x+q.'''\n",
    "\n",
    "    # First some conversion in data types, such that they can be fed to Scikit estimators\n",
    "    LEFT, RIGHT = 0, 1\n",
    "    segment_endpoints_x = [[], []]  # The list will accumulate the x coordinate of all identified segment endpoints,\n",
    "    # partitioned into two sub-lists, one for points belonging to the left side, and one for the right side\n",
    "    segment_endpoints_y = [[], []]  # Same as above, but for the y coordinates\n",
    "    for segment in segments:\n",
    "        slope = line_slope(segment[0], segment[1], segment[2], segment[3])\n",
    "        # On the pavement there can be nearly horizontal segments (i.e. with slope close to 0) that\n",
    "        # don't belong to lane marks and would throw off the interpolation, and are therefore discarded\n",
    "        if abs(slope) < min_slope:\n",
    "            continue\n",
    "        side = LEFT if slope < 0 else RIGHT\n",
    "        segment_endpoints_x[side].append([segment[0]])\n",
    "        segment_endpoints_x[side].append([segment[2]])\n",
    "        segment_endpoints_y[side].append(segment[1])\n",
    "        segment_endpoints_y[side].append(segment[3])\n",
    "\n",
    "    # Go ahead and interpolate the points with two lines, one for the left side and one of the right side\n",
    "\n",
    "    def get_x_from_y(y, m, q):\n",
    "        \"\"\"\n",
    "        Returns x such that y=m*x+q if it exists, otherwise return the largest Python floating point number\n",
    "        \"\"\"\n",
    "        return (y - q) / m if m != 0 else sys.float_info.max\n",
    "\n",
    "    lanes = []  # Initialize the return value\n",
    "    for side in (LEFT, RIGHT):\n",
    "        # If no left/right line was detected, then just skip ahead; i.e. don't try to fit and draw it in this image\n",
    "        if len(segment_endpoints_x[side]) == 0:\n",
    "            continue\n",
    "        # Set the random number generator seed used by RANSAC, to make experiments reproducible\n",
    "        estimator = linear_model.RANSACRegressor(base_estimator=linear_model.LinearRegression(), min_samples=2,\n",
    "                                                 random_state=2111970)\n",
    "        # The Scikit pipeline is not strictly necessary for least means-square linear interpolation, but it makes it\n",
    "        # easier to replace the estimator used, and change the degree of the polynomial approximation\n",
    "        model = make_pipeline(PolynomialFeatures(1), estimator)\n",
    "        model.fit(segment_endpoints_x[side], segment_endpoints_y[side])\n",
    "        # The segment to be drawn over the line shall extend (in height) from y=top_y to y=bottom_y\n",
    "        top_y = min(vertices[1][1], vertices[2][1])\n",
    "        bottom_y = max(vertices[0][1], vertices[3][1])\n",
    "        # Fetch the coordinates of two points (x0, y0) and (x1, y1) that belong to the lane line\n",
    "        x0, x1 = (vertices[0][0], vertices[1][0]) if side == LEFT else (vertices[3][0], vertices[2][0])\n",
    "        y0 = model.predict(x0)[0]\n",
    "        y1 = model.predict(x1)[0]\n",
    "        # Take a segment from the lane line with y coordinate ranging between top_y and bottom_y (i.e. clip/extend\n",
    "        # the segment (x0, y0)-(x1, y1) as necessary)\n",
    "        m = line_slope(x0, y0, x1, y1)\n",
    "        q = line_intercept(x0, y0, x1, y1)\n",
    "        top_x = int(round(get_x_from_y(top_y, m, q)))\n",
    "        bottom_x = int(round(get_x_from_y(bottom_y, m, q)))\n",
    "        lanes.append((bottom_x, bottom_y, top_x, top_y))\n",
    "\n",
    "    return lanes\n",
    "\n",
    "\n",
    "def get_vertices(image):\n",
    "    \"\"\"\n",
    "    Returns a list of vertices for the mask, suitable to identify lanes in the image\n",
    "    \"\"\"\n",
    "    height, width, _ = image.shape\n",
    "    chop_top_w = .42  # The distance of the 2nd vertex of the mask from the left border of the image,\n",
    "    # and of the 3rd vertex from the right border, expressed as a fraction of the horizontal image size\n",
    "    chop_top_h = .61  # The distance of the 2nd and 3rd vertex of the mask from the top border of the image,\n",
    "    # expressed as a fraction of the vertical image size\n",
    "    chop_bottom_w = .11  # The distance of the 1st and 4th vertex of the mask from the left and right image border\n",
    "    # respectively\n",
    "    vertices = np.array([[(width * chop_bottom_w, height), (width * chop_top_w, height * chop_top_h),\n",
    "                          (width - width * chop_top_w, height * chop_top_h), (width * (1 - chop_bottom_w), height)]],\n",
    "                        dtype=np.int32)\n",
    "    return vertices[0]\n",
    "\n",
    "\n",
    "def draw_segments(image, segments, color, thickness):\n",
    "    \"\"\"\n",
    "    Draws the listed segments with the given RGB color and thickness (in pixels) over an image with the same\n",
    "    shape as `image`, and return it. The image passed as input parameter is used only to determine the shape, and is\n",
    "    not altered.\n",
    "    \"\"\"\n",
    "    segments_image = np.zeros((image.shape[0], image.shape[1], 3), dtype=np.uint8)  # initialize the return value\n",
    "    for x0, y0, x1, y1 in segments:\n",
    "        cv2.line(segments_image, (x0, y0), (x1, y1), color, thickness)\n",
    "    return segments_image\n",
    "\n",
    "\n",
    "def get_Hough_params():\n",
    "    \"\"\"\n",
    "    A utility function that returns parameters usable to call get_Hough_segments().\n",
    "    Multiple calls to that function can easly share the same parameter values, if desired.\n",
    "    \"\"\"\n",
    "    return {'kernel_size': 3,  # For the Gaussian blur\n",
    "            'threshold1': 100,  # Lowest threshold for Canny edge detection\n",
    "            'threshold2': 200,  # Highest threshold for Canny edge detection\n",
    "            'rho': 1,  # Distance resolution for Hough transform (pixels)\n",
    "            'theta': np.pi / 720,  # Angular resolution for Hough transform (radians)\n",
    "            'min_votes': 25,  # Min number of votes for Hough transoform\n",
    "            'min_line_length': 10,  # Min segment length (pixels) for Hough transform\n",
    "            'max_line_gap': 50}  # Max allowed distance (pixels) between connectable segments for Hough transform\n",
    "\n",
    "\n",
    "def process_lanes_detection(image):\n",
    "    \"\"\"\n",
    "    Return an image same as `image` but with the lane markings (if detected) drawn over it\n",
    "    \"\"\"\n",
    "    vertices = get_vertices(image)\n",
    "    segments = get_Hough_segments(image, vertices, **get_Hough_params())\n",
    "    lanes = get_lanes(segments, vertices, 0.3)\n",
    "    image_with_lanes = draw_segments(image, lanes, [255, 0, 0], 5)\n",
    "    output_image = weighted_img(image_with_lanes, image)\n",
    "    return output_image\n",
    "\n",
    "\n",
    "def process_segments_detection(image):\n",
    "    \"\"\"\n",
    "    Return an image same as `image` but with segments candidate to be edges of lane markings drawn over it\n",
    "    \"\"\"\n",
    "    vertices = get_vertices(image)\n",
    "    segments = get_Hough_segments(image, vertices, **get_Hough_params())\n",
    "    image_with_segments = draw_segments(image, segments, [255, 0, 0], 2)\n",
    "    output_image = weighted_img(image_with_segments, image)\n",
    "    # To help debugging the edge detection step, uncomment the line below\n",
    "    # output_image = cv2.cvtColor(masked,cv2.COLOR_GRAY2BGR)\n",
    "    return output_image\n",
    "\n",
    "\n",
    "def main():\n",
    "    plt.interactive(False)  # For debugging within PyCharm\n",
    "\n",
    "    def process_test_images():\n",
    "        \"\"\"\n",
    "        Process the individual JPEG test images found in ./test_images directory (detect lane markings),\n",
    "        and write the output as PNG files in the same directory\n",
    "        \"\"\"\n",
    "        input_fnames = os.listdir('test_images')\n",
    "        input_fnames = [fname for fname in input_fnames if fname.endswith('.jpg')]\n",
    "\n",
    "        for fname in input_fnames:\n",
    "            # load the image\n",
    "            image = mpimg.imread('test_images/' + fname)\n",
    "            # do your thing\n",
    "            processed_image = process_lanes_detection(image)\n",
    "            # save the image\n",
    "            ext_stripped, _ = os.path.splitext(fname)\n",
    "            mpimg.imsave('test_images/' + ext_stripped + '.png', processed_image, format='png')\n",
    "\n",
    "    # Process the MP4 video clips in ./test_clips and write the output in ./output_clips\n",
    "    input_fnames = os.listdir('test_clips')\n",
    "    input_fnames = [fname for fname in input_fnames if fname.endswith('.mp4')]\n",
    "\n",
    "    for fname in input_fnames:\n",
    "        ext_stripped, _ = os.path.splitext(fname)\n",
    "        clip = VideoFileClip('test_clips/' + fname)\n",
    "        output_clip_segments = clip.fl_image(process_segments_detection)\n",
    "        output_clip_segments.write_videofile('output_clips/' + ext_stripped + '_segments.mp4', audio=False)\n",
    "        output_clip_segments = clip.fl_image(process_lanes_detection)\n",
    "        output_clip_segments.write_videofile('output_clips/' + ext_stripped + '_lanes.mp4', audio=False)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Let's play the output video clips. They are found in directory ./test_clips\n",
    "For each pair of clips, the first one shows the output of segments detection; each segment highlighted here is candidate to be part of a lane marking. The second in the pair shows the output of the whole processing, with the detected lane markings highlighted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Detected segments for \"solidWhiteRight.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format('output_clips/solidWhiteRight_segments.mp4'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Detected lanes for \"solidWhiteRight.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format('output_clips/solidWhiteRight_lanes.mp4'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Detected segments for \"solidYellowLeft.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format('output_clips/solidYellowLeft_segments.mp4'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Detected lanes for \"solidYellowLeft.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format('output_clips/solidYellowLeft_lanes.mp4'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Detected segments for \"challenge.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format('output_clips/challenge_segments.mp4'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Detected lanes for \"challenge.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format('output_clips/challenge_lanes.mp4'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
